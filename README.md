# ğŸŒ Language Detection Project â€“ NLP with Multinomial Naive Bayes  

This project focuses on **automatic text language detection** using **Multinomial Naive Bayes** and **TF-IDF Vectorization**. The model is trained on a **custom dataset** with 14 languages, including **English, Spanish, French, Polish**, and more.  

<p align="center">
  <img src="https://img.shields.io/badge/Naive--Bayes-228B22?style=for-the-badge&logo=scikitlearn&logoColor=white" alt="Naive Bayes"/>
  <img src="https://img.shields.io/badge/Web%20Scraping-FF4500?style=for-the-badge&logo=web&logoColor=white" alt="Web Scraping"/>
  <img src="https://img.shields.io/badge/BeautifulSoup-4B275F?style=for-the-badge&logo=beautifulsoup&logoColor=white" alt="BeautifulSoup"/>
  <img src="https://img.shields.io/badge/Pandas-150458?style=for-the-badge&logo=pandas&logoColor=white" alt="Pandas"/>
  <img src="https://img.shields.io/badge/Numpy-013243?style=for-the-badge&logo=numpy&logoColor=white" alt="NumPy"/>
  <img src="https://img.shields.io/badge/Matplotlib-11557C?style=for-the-badge&logo=plotly&logoColor=white" alt="Matplotlib"/>
    <img src="https://img.shields.io/badge/Docker-11557C?style=for-the-badge&logo=plotly&logoColor=white" alt="Docker"/>
  <img src="https://img.shields.io/badge/Python-3776AB?style=for-the-badge&logo=python&logoColor=white" alt="Python"/>
  <img src="https://img.shields.io/badge/FastAPI-009688?style=for-the-badge&logo=fastapi&logoColor=white" alt="FastAPI"/>
  <img src="https://img.shields.io/badge/Docker-2496ED?style=for-the-badge&logo=docker&logoColor=white" alt="Docker"/>
  <img src="https://img.shields.io/badge/Scikit--Learn-F7931E?style=for-the-badge&logo=scikitlearn&logoColor=white" alt="Scikit-learn"/>
</p>

---


## ğŸ” **Project Description**  

The primary goal of this project is to **automatically detect the language** of short text samples using **Natural Language Processing (NLP)** techniques. The dataset was created by **web scraping** multilingual text from **Wikipedia**, followed by **TF-IDF Vectorization** and **Multinomial Naive Bayes** for classification.  


âœ… **API Ready** â€“ Built with **FastAPI** for real-time language detection.  
âœ… **Dockerized** â€“ Fully containerized for seamless deployment.  
âœ… **Custom Dataset** â€“ Web scraped text data from Wikipedia for multilingual training. 

---

## ğŸ—ï¸ **Project Structure**  

### ğŸ“¥ **1. Custom Dataset Creation**  
âœ” **Web scraping** text data from Wikipedia in **14 languages**.  
âœ” Topics include **Wikipedia**, **Pi**, **Microsoft**, **Adidas**, and others.  

### ğŸ§¹ **2. Text Cleaning & Preprocessing**  
âœ” Removed **special characters** and **digits** for consistent preprocessing.  
âœ” **TF-IDF vectorization** with **unigrams** and **bigrams** for feature extraction.  

### ğŸ“Š **3. Data Visualization**  
âœ” Showcased **language distribution** in the dataset using **seaborn** and **matplotlib**.  

### ğŸƒ **4. Model Training**  
âœ” Used **Multinomial Naive Bayes** for classification.  
âœ” **Hyperparameter tuning** (alpha) via **GridSearchCV**.  

### ğŸ“ˆ **5. Model Evaluation**  
âœ” Evaluated performance using:  
- **Confusion matrix**  
- **Classification report**  
- **Accuracy score**  

### ğŸŒ **6. API Development (FastAPI)**  
âœ” Developed a **FastAPI** application for real-time language detection.  
âœ” Hosted using **Uvicorn**, with an **interactive web interface** for user input.  

### ğŸ³ **7. Dockerization**  
âœ” **Containerized** the entire project using **Docker**.  
âœ” Ensures **portability** and **easy deployment** across different environments.  

---
## ğŸš€ Project Structure  

```bash
ğŸ“¦ Language_Detection
â”œâ”€â”€ ğŸ“ input
â”‚   â”œâ”€â”€ Sample_Language.csv                             # My Scrap Dataset 
â”œâ”€â”€ ğŸ“ app
â”‚   â”œâ”€â”€ ğŸ“ templates
â”‚   â”‚   â”œâ”€â”€ index.html
â”‚   â”œâ”€â”€ ğŸ“ model
â”‚   â”‚   â”œâ”€â”€ Pipeline_and_model_Language_Detection-0.1.0.pkl # Model 
â”‚   â”œâ”€â”€ ğŸ main.py
â”œâ”€â”€ ğŸ“ notebooks
â”‚   â”œâ”€â”€ Language_Detection__Web_Scraping.ipynb          # Web_Scraping
â”‚   â”œâ”€â”€ Language_Detection_TfidfVectorizer.ipynb        # Analysis Preprocessing, Training
â”œâ”€â”€ ğŸ“„ README.md
â”œâ”€â”€ ğŸ³ Dockerfile           # Container configuration
â”œâ”€â”€ ğŸ“› .dockerignore        # Docker exclusion rules
â”œâ”€â”€ ğŸ“› .gitignore           # Git exclusion rules
â””â”€â”€ ğŸ“œ requirements.txt     # requirements
```
---

## ğŸ›  **Technologies & Tools**  


## ğŸ› ï¸ **Technologies & Tools**  

| **Category**           | **Tools & Libraries**                      |
|--------------------------|------------------------------------------|
| **Programming Language** | Python                                   |
| **Web Scraping**          | BeautifulSoup, requests                  |
| **Data Manipulation**     | pandas, numpy                            |
| **Machine Learning**      | scikit-learn (TF-IDF, Naive Bayes)       |
| **API Development**       | FastAPI, Uvicorn                         |
| **Dockerization**         | Docker                                   |
| **Visualization**         | seaborn, matplotlib                      |
---

## ğŸ—ï¸ Build and Run with Docker:  

```bash
# Clone repository
git clone https://github.com/marti0001/MNIST-Digit-Classification

# Build Docker image
docker build -t language_detection_app .

# Run container
docker run -p 8000:8000 language_detection_app

#Open your browser and go to
http://localhost:8000
```
