{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37d2c6cf-be5c-4d7a-98d2-292f5853b8e4",
   "metadata": {},
   "source": [
    "# Web scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c51746b4-8b3f-4917-b78d-c7e9a50e9a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ee715a8-1b6f-40ef-a241-388819231f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\n",
    "    'referer': 'https://www.scrapingcourse.com/ecommerce/',\n",
    "    'accept-language': 'en-US,en;q=0.9',\n",
    "    'content-type': 'application/json',\n",
    "    'accept-encoding': 'gzip, deflate, br',\n",
    "    'sec-ch-device-memory': '8',\n",
    "    'sec-ch-ua': '\"Google Chrome\";v=\"125\", \"Chromium\";v=\"125\", \"Not.A/Brand\";v=\"24\"',\n",
    "    'sec-ch-ua-platform': \"Windows\",\n",
    "    'sec-ch-ua-platform-version': '\"10.0.0\"',\n",
    "    'sec-ch-viewport-width': '792',\n",
    "    'User-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/125.0.0.0 Safari/537.36'\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b934019c-a2a5-473f-8fbc-cb6b5df16d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_page(url):\n",
    "    response = requests.get(url, headers= headers, timeout=10)\n",
    "    if response.status_code ==200:\n",
    "        return response.text\n",
    "    else:\n",
    "        print(f\"Błąd {response.status_code} przy pobraniu strony {url}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "bcd76fda-f934-486e-ae20-8f793b364d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "English = []  # English\n",
    "Spanish = []  # Spanish\n",
    "French = []  # French\n",
    "German = []  # German\n",
    "Italian = []  # Italian\n",
    "Portuguese = []  # Portuguese\n",
    "Russian = []  # Russian\n",
    "Polish = []  # Polish\n",
    "Ukrainian = []  # Ukrainian\n",
    "Dutch = []  # Dutch\n",
    "Swedish = []  # Swedish\n",
    "Finnish = []  # Finnish\n",
    "Norwegian = []  # Norwegian\n",
    "Danish = []  # Danish\n",
    "\n",
    "# Creating a nested list\n",
    "data_list = [English, Spanish, French, German, Italian, Portuguese, Russian, Polish, Ukrainian, Dutch, Swedish, Finnish, Norwegian, Danish]\n",
    "\n",
    "# Wikipedia language codes (ISO 639-1)\n",
    "language_codes = [\"en\", \"es\", \"fr\", \"de\", \"it\", \"pt\", \"ru\", \"pl\", \"uk\", \"nl\", \"sv\", \"fi\", \"no\", \"da\"]\n",
    "\n",
    "language_names = [\"English\", \"Spanish\", \"French\", \"German\", \"Italian\", \"Portuguese\", \n",
    "                 \"Russian\", \"Polish\", \"Ukrainian\", \"Dutch\", \"Swedish\", \"Finnish\", \n",
    "                 \"Norwegian\", \"Danish\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "a530c5cf-4f0c-4a95-b1be-25e1efb02c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_list = ['Wikipedia', 'Pi','Omega', 'Amazon','Microsoft', 'Audi','Adidas']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "81623746-829e-4f56-ac10-10de326b32a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def web_scrap(topic):\n",
    "    \n",
    "    for i in range(len(language_codes)):\n",
    "        url = f\"https://{language_codes[i]}.wikipedia.org/wiki/{topic}\"\n",
    "        soup = BeautifulSoup(get_page(url),'html.parser')\n",
    "        result_container = soup.find_all(\"p\")\n",
    "        for result in result_container:\n",
    "            text = result.text.strip()\n",
    "            data_list[i].append(text)\n",
    "    return 'finish'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "f543995c-3626-42e5-9d03-dd4c6e2255a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataframe():\n",
    "    data = []\n",
    "    for lang_name, lang_data in zip(language_names, data_list):\n",
    "        for text in lang_data:\n",
    "            data.append((text, lang_name))\n",
    "    \n",
    "    df = pd.DataFrame(data, columns=['Text', 'Language'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "c75f37f4-3db8-476a-8cf1-2f4f971c1918",
   "metadata": {},
   "outputs": [],
   "source": [
    "for topic in topic_list:\n",
    "    scrap = web_scrap(topic)\n",
    "df = create_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "f6274f41-ddb7-4c2a-b1b7-7abe40d88b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('..\\input\\Sample_Language.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
